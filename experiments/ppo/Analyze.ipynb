{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d665e0-05e1-4636-be55-bb47ed88aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import tyro\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from agent import Agent\n",
    "from mani_skill.utils.wrappers.flatten import FlattenActionSpaceWrapper\n",
    "from mani_skill.utils.wrappers.record import RecordEpisode\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "from mani_skill.utils import gym_utils\n",
    "\n",
    "from twsim.envs import plane  # noqa: F401\n",
    "from twsim.robots import transwheel  # noqa: F401\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf00f8e-2c8f-43bf-8013-7090170d7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    \"Evaluate a trained policy.\"\n",
    "\n",
    "    # fmt: off\n",
    "\n",
    "    checkpoint: str                          # Path to the checkpoint file\n",
    "    env_id: str                              # Environment ID\n",
    "    control_mode: str = \"wheel_vel_ext_pos\"  # Control mode\n",
    "    capture_video: bool = True               # Save videos to ./runs/{run_name}/test_videos\n",
    "    num_eval_envs: int = 1                   # Number of parallel evaluation environments\n",
    "    num_eval_steps: int = 500                # Number of steps to run in each evaluation environment\n",
    "    eval_reconfiguration_freq: int = 1       # Reconfigure the environment each reset to ensure objects are randomized\n",
    "    eval_partial_reset: bool = False         # Let parallel evaluation environments reset upon termination instead of truncation\n",
    "    cuda: bool = True                        # Use GPU for evaluation\n",
    "\n",
    "    # fmt: on\n",
    "\n",
    "# checkpoint = 'runs/Stiffer/final_ckpt.pt'\n",
    "# checkpoint = 'runs/PlaneVel-v1__train-ppo__1__1747949506/final_ckpt.pt'\n",
    "# checkpoint = 'runs/Step/final_ckpt.pt'\n",
    "# checkpoint = 'runs/StepEnv/final_ckpt.pt'\n",
    "checkpoint = 'runs/SensorEnvLongLong/ckpt_576.pt'\n",
    "\n",
    "# env_id = 'StepVel-v1'\n",
    "env_id = 'StepVelSensor-v1'\n",
    "\n",
    "args = Args(checkpoint, env_id)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "env_kwargs = dict(\n",
    "    obs_mode=\"state\",\n",
    "    render_mode=\"rgb_array\",\n",
    "    sim_backend=\"physx_cuda\",\n",
    "    control_mode=args.control_mode,\n",
    "    human_render_camera_configs=dict(shader_pack=\"rt\"),\n",
    ")\n",
    "\n",
    "eval_output_dir = Path(args.checkpoint).parent / env_id\n",
    "\n",
    "overwrite = True\n",
    "print('Checking', eval_output_dir)\n",
    "if (not overwrite) and eval_output_dir.exists():\n",
    "    raise SystemError(\"Make sure that you are not overwriting existing output.\")\n",
    "\n",
    "\n",
    "eval_output_dir = str(eval_output_dir)\n",
    "print(f\"Saving eval videos to {eval_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37fec1-5356-4d8b-a008-82fd533115c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the evaluation environment\n",
    "eval_envs = gym.make(\n",
    "    args.env_id,\n",
    "    num_envs=args.num_eval_envs,\n",
    "    reconfiguration_freq=args.eval_reconfiguration_freq,\n",
    "    **env_kwargs,  # type: ignore\n",
    ")\n",
    "\n",
    "# Flatten action spaces if needed\n",
    "if isinstance(eval_envs.action_space, gym.spaces.Dict):\n",
    "    eval_envs = FlattenActionSpaceWrapper(eval_envs)\n",
    "\n",
    "eval_envs = RecordEpisode(\n",
    "    eval_envs,  # type: ignore\n",
    "    output_dir=eval_output_dir,\n",
    "    save_trajectory=False,\n",
    "    max_steps_per_video=args.num_eval_steps,\n",
    "    video_fps=30,\n",
    ")\n",
    "\n",
    "eval_envs = ManiSkillVectorEnv(\n",
    "    eval_envs,  # type: ignore\n",
    "    args.num_eval_envs,\n",
    "    ignore_terminations=not args.eval_partial_reset,\n",
    "    record_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73f549-56eb-4564-9240-68f27adc07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_envs.unwrapped.print_sim_details()  # type: ignore\n",
    "print(f\"{eval_envs.unwrapped.reward_mode=}\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5591e8-3edb-4f9e-9fa4-78520444140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating\")\n",
    "\n",
    "labels = [\"elapsed_steps\", \"velx\", \"vely\", \"velz\", \"vel\", \"velocity_error\", \"reward_velocity\", \"extension\", \"reward_extension\", \"reward\", \"contact\", \"distance\"]\n",
    "df_rows = []\n",
    "\n",
    "eval_obs, _ = eval_envs.reset()\n",
    "num_episodes = 0\n",
    "\n",
    "observation_shape = eval_envs.single_observation_space.shape\n",
    "action_shape = eval_envs.single_action_space.shape\n",
    "\n",
    "agent = Agent(observation_shape, action_shape).to(device)\n",
    "agent.load_state_dict(torch.load(args.checkpoint))\n",
    "agent.eval()\n",
    "\n",
    "num_steps = min(gym_utils.find_max_episode_steps_value(eval_envs._env), args.num_eval_steps)\n",
    "\n",
    "for step in tqdm(range(num_steps)):\n",
    "    with torch.no_grad():\n",
    "        eval_action = agent.get_action(eval_obs, deterministic=True)\n",
    "        eval_obs, eval_reward, _, _, eval_infos = eval_envs.step(eval_action)\n",
    "            \n",
    "        if \"final_info\" in eval_infos:\n",
    "            mask = eval_infos[\"_final_info\"]\n",
    "            num_episodes += mask.sum()\n",
    "            break\n",
    "\n",
    "        eval_infos[\"velx\"] = eval_infos[\"velocity\"].squeeze()[0]\n",
    "        eval_infos[\"vely\"] = eval_infos[\"velocity\"].squeeze()[1]\n",
    "        eval_infos[\"velz\"] = eval_infos[\"velocity\"].squeeze()[2]\n",
    "        eval_infos[\"vel\"] =  eval_infos[\"velocity\"].squeeze().norm()\n",
    "\n",
    "        if \"distance\" in eval_infos:\n",
    "            eval_infos[\"contact\"] = eval_infos[\"distance\"] < 0.01\n",
    "            \n",
    "        eval_infos[\"reward\"] = eval_reward\n",
    "    \n",
    "        df_rows.append({l: eval_infos[l].item() for l in labels if l in eval_infos})\n",
    "\n",
    "total_eval_steps = args.num_eval_steps * args.num_eval_envs\n",
    "print(f\"Evaluated {step} steps resulting in {num_episodes} episodes\")\n",
    "\n",
    "eval_envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a28289-b783-4b57-a708-962842b12cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a69c79-719c-488e-8377-66f4c0dac7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2099c39-75ca-4e43-85ae-5879c1d36e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = [[\"vel\", \"velx\"], [\"vely\", \"velz\"], [\"velocity_error\", \"reward_velocity\"], [\"extension\", \"reward_extension\"], [\"reward\", \"contact\"], [\"distance\"]]\n",
    "limits = [[0, 0.4]] * 5 + [[0, 1]] + [[-10, 10]] + [[0, 1]] * 4\n",
    "\n",
    "num_rows = len(to_plot)\n",
    "num_cols = len(to_plot[0])\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "labels = [l for row in to_plot for l in row]\n",
    "\n",
    "for ax, label, lims in zip(axes.flatten(), labels, limits):\n",
    "    if label not in df.columns: print('Skipping', label); continue\n",
    "    sns.lineplot(ax=ax, data=df, x=\"elapsed_steps\", y=label)\n",
    "    ax.set_ylim(lims)\n",
    "    print(label, lims)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5e4cc-0373-4679-9c8b-6c8883f94762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mani2)",
   "language": "python",
   "name": "mani2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
